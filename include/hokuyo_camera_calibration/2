#include <ros/ros.h>
#include <pcl_ros/point_cloud.h>
#include <pcl/point_types.h>

#include <opencv2/opencv.hpp>
#include <cv_bridge/cv_bridge.h>

#include <image_geometry/pinhole_camera_model.h>

#include <sensor_msgs/CameraInfo.h>
#include <sensor_msgs/PointCloud2.h>

#include <message_filters/subscriber.h>
#include <message_filters/synchronizer.h>
#include <message_filters/sync_policies/approximate_time.h>

#include <amsl_recog_msgs/ObjectInfoWithROI.h>
#include <amsl_recog_msgs/ObjectInfoArray.h>

using namespace std;
using namespace sensor_msgs;
using namespace amsl_recog_msgs;

ros::Publisher pub;

struct BBox{
    Vector3f p1;
    Vector3f p2;
    Vector3f p3;
    Vector3f p4;
};

struct Data{
    cv::Rect bbox;
    cv::Rect cluster;
    cv::Rect overlap;
    
    int bbox_size;
    int cluster_size;
    int overlap_size;
    int union_size;
    
    float iou;
};

void get_bbox_data(const amsl_recog_msgs::ObjectInfoWithROI cluster, BBox& bbox)
{
    Vector3f centroid;
    centroid[0] = cluster.pose.position.x; //depth 
    centroid[1] = cluster.pose.position.y; //width
    centroid[2] = cluster.pose.position.z; //height

    float depth  = cluster.depth;
    float width  = cluster.width;
    float height = cluster.height;
    
    // depthはcentroidの値を利用する
    bbox.p1[0] = centroid[0];
    bbox.p1[1] = centroid[1] + width/2;
    bbox.p1[2] = centroid[2] + height/2;

    bbox.p2[0] = centroid[0];
    bbox.p2[1] = centroid[1] - width/2;
    bbox.p2[2] = centroid[2] + height/2;

    bbox.p3[0] = centroid[0];
    bbox.p3[1] = centroid[1] + width/2;
    bbox.p3[2] = centroid[2] - height/2;

    bbox.p4[0] = centroid[0];
    bbox.p4[1] = centroid[1] - width/2;
    bbox.p4[2] = centroid[2] - height/2;
}

void roi_for_cluster(const ObjectInfoArrayConstPtr cluster_msg,
                     const image_geometry::PinholeCameraModel cam_model_,
                     ObjectInfoArray& cluster_roi,
                     cv::Mat &image)
{
    int cluster_size = int(cluster_msg->object_array.size());
    for(int i=0;i<cluster_size; i++)
    {
        ObjectInfoWithROI cluster = cluster_msg->object_array[i];
        BBox bbox;
        get_bbox_data(cluster, bbox);
        
        // BBox (PointCloud)
        cv::Point3d pt_cv1(-bbox.p1[1], -bbox.p1[2], bbox.p1[0]);
        cv::Point3d pt_cv4(-bbox.p4[1], -bbox.p4[2], bbox.p4[0]);
        // BBox (Image)
        cv::Point2d uv1 = cam_model_.project3dToPixel(pt_cv1);
        cv::Point2d uv4 = cam_model_.project3dToPixel(pt_cv4);

        ObjectInfoWithROI roi;
        roi.roi.x_offset = uv1.x;
        roi.roi.y_offset = uv1.y;
        roi.roi.width    = uv4.x-uv1.x;
        roi.roi.height   = uv4.y-uv1.y;
        roi.width     = cluster.width;
        roi.height    = cluster.height;
        roi.depth     = cluster.depth;
        roi.pose      = cluster.pose;
        roi.points    = cluster.points;
        cluster_roi.object_array.push_back(roi);

        cv::line(image, cv::Point(uv1.x, uv1.y), cv::Point(uv4.x, uv4.y), cv::Scalar(0,0,200), 3, 4);
    }
}

void roi_for_bbox(const ObjectInfoArrayConstPtr bbox_msg,
                  ObjectInfoArray& bbox_roi,
                  cv::Mat& image)
{
    int bbox_size = int(bbox_msg->object_array.size());
    for(int i=0;i<bbox_size;i++){
        ObjectInfoWithROI bbox = bbox_msg->object_array[i];

        if(bbox.Class!="person") continue;
        
        ObjectInfoWithROI roi;
        roi.Class        = bbox.Class;
        roi.probability  = bbox.probability;
        roi.roi.x_offset = bbox.xmin;
        roi.roi.y_offset = bbox.ymin;
        roi.roi.width    = bbox.xmax - bbox.xmin;
        roi.roi.height   = bbox.ymax - bbox.ymin;
        bbox_roi.object_array.push_back(roi);
        cv::rectangle(image,cv::Point(bbox.xmin, bbox.ymin),cv::Point(bbox.xmax, bbox.ymax),cv::Scalar(0,200,0), 3, 4);
    }
}

